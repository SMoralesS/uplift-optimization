{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from causalml.inference.meta import BaseTClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "from causalml.dataset import make_uplift_classification, synthetic_data\n",
    "from causalml.inference.tree import UpliftRandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X_names = make_uplift_classification(\n",
    "    n_samples=10000, treatment_name=[\"control\", \"treatment1\", \"treatment2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"conversion\"\n",
    "T = \"treatment_group_key\"\n",
    "control = 0\n",
    "X = [col for col in df.columns if col not in [y, \"conversion\"] and \"informative\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_encoder = OrdinalEncoder()\n",
    "df[T] = T_encoder.fit_transform(df[T].to_numpy().reshape(-1, 1)).astype(int)\n",
    "T_encoder = OrdinalEncoder()\n",
    "df[T] = T_encoder.fit_transform(df[T].to_numpy().reshape(-1, 1)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_dict = {0: 0, 1: 5, 2: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XLearner():\n",
    "    # first stage models\n",
    "\n",
    "    response_models = {}\n",
    "    for t in train[T].unique():\n",
    "        m = LGBMClassifier(max_depth=2, min_child_samples=30)\n",
    "        m.fit(train.query(f\"{T}=={t}\")[X], train.query(f\"{T}=={t}\")[y])\n",
    "        response_models[t] = m\n",
    "\n",
    "    # propensity model\n",
    "    e = LGBMClassifier(solver=\"lbfgs\", penalty=\"none\")\n",
    "    e.fit(train[X], train[T])\n",
    "\n",
    "    psuedo_models = {}\n",
    "    for t in train[T].unique():\n",
    "        mj = response_models[t]\n",
    "        m0 = response_models[control]\n",
    "\n",
    "        control_df = train[(train[T] == control)]\n",
    "        treatment_df = train[(train[T] == t)]\n",
    "\n",
    "        s_t0 = np.ones(control_df.shape[0]) * cost_dict[control]\n",
    "        s_tj = np.ones(treatment_df.shape[0]) * cost_dict[t]\n",
    "\n",
    "        ic_t0 = np.ones(control_df.shape[0]) * 0.1\n",
    "        ic_tj = np.ones(treatment_df.shape[0]) * 0.1\n",
    "\n",
    "        D_t0 = (control_df[\"value\"] - s_t0) * (\n",
    "            mj.predict(control_df[X]) - control_df['value'] * control_df[y]\n",
    "        ).to_numpy() - ic_t0\n",
    "\n",
    "        D_tj = (treatment_df[\"value\"] - s_tj) * (\n",
    "            treatment_df[y] - treatment_df['value'] * m0.predict(treatment_df[X])\n",
    "        ).to_numpy() - ic_tj\n",
    "\n",
    "        t0_effect_key = f\"{control}_{t}\"\n",
    "        tj_effect_key = f\"{t}_{control}\"\n",
    "\n",
    "        psuedo_models[t0_effect_key] = LGBMRegressor(\n",
    "            max_depth=2, min_child_samples=30\n",
    "        ).fit(train[train[T] == control][X], D_t0)\n",
    "\n",
    "        psuedo_models[tj_effect_key] = LGBMRegressor(\n",
    "            max_depth=2, min_child_samples=30\n",
    "        ).fit(train[train[T] == t][X], D_tj)\n",
    "\n",
    "    probs = e.predict_proba(train[X])\n",
    "\n",
    "    cate_tracker = {}\n",
    "    for t in train[T].unique():\n",
    "        if t == control:\n",
    "            continue\n",
    "        tau0_key = f\"{control}_{t}\"\n",
    "        tauj_key = f\"{t}_{control}\"\n",
    "\n",
    "        denom = probs[:, control] + probs[:, t]\n",
    "        cate = probs[:, t] / denom * psuedo_models[tau0_key].predict(train[X]) + probs[\n",
    "            :, control\n",
    "        ] * psuedo_models[tauj_key].predict(train[X])\n",
    "        cate_tracker[t] = cate\n",
    "\n",
    "    train_preds = pd.DataFrame(cate_tracker)\n",
    "    train_preds[0] = 0\n",
    "\n",
    "    probs = e.predict_proba(test[X])\n",
    "\n",
    "    cate_tracker = {}\n",
    "    for t in test[T].unique():\n",
    "        if t == control:\n",
    "            continue\n",
    "        tau0_key = f\"{control}_{t}\"\n",
    "        tauj_key = f\"{t}_{control}\"\n",
    "\n",
    "        denom = probs[:, control] + probs[:, t]\n",
    "        cate = probs[:, t] / denom * psuedo_models[tau0_key].predict(test[X]) + probs[\n",
    "            :, control\n",
    "        ] * psuedo_models[tauj_key].predict(test[X])\n",
    "        cate_tracker[t] = cate\n",
    "\n",
    "    test_preds = pd.DataFrame(cate_tracker)\n",
    "    test_preds[0] = 0\n",
    "\n",
    "    # x_cate_test = cate_tracker.max(axis=1)\n",
    "    # treatment_test = cate_tracker.idxmax(axis=1)\n",
    "    return train_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds, test_preds = XLearner()\n",
    "X_best_ite = test_preds.idxmax(axis=1)\n",
    "X_best_ite_train = train_preds.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['trigger_cost'] = test.treatment_group_key.apply(lambda x: cost_dict[x])\n",
    "test['actual_value'] = (test['value'] - test['trigger_cost']) * test['conversion'] - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.008173076923077"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.treatment_group_key == test_preds.idxmax(axis=1)].actual_value.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.83843661401377"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_preds = pd.Series(np.random.choice([0, 1, 2], test.shape[0]), index=test.index)\n",
    "test[test.treatment_group_key == random_preds].actual_value.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db47acd11efc28b5ae79a6325446a19ac2632e6052cb03ca38bb5587ba68be46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
